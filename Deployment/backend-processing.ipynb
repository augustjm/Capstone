{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b83a224c",
   "metadata": {},
   "source": [
    "# Building a simple chatbot using LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc96d46",
   "metadata": {},
   "source": [
    "## Import libraries, API and set filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9888248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install llama-index==0.8.12 pypdf sentence-transformers ragas openai\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"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\" # replace with your API key\n",
    "\n",
    "from llama_index import Document, GPTVectorStoreIndex, ServiceContext\n",
    "from llama_index.readers import BeautifulSoupWebReader, SimpleDirectoryReader\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.evaluation import DatasetGenerator\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd1be0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set filepath to my data directory \n",
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.join(current_dir, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99211f6b",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "According to [LlamaIndex's documentation](https://gpt-index.readthedocs.io/en/latest/examples/data_connectors/simple_directory_reader.html), the `SimpleDirectoryReader` is the most commonly used data connector that just works. Simply pass in a input directory or a list of files. It will select the best file reader based on the file extensions. \n",
    "\n",
    "In this use case here, there are csv files of TripAdvisor bar reviews, which are not included in gpt-3.5-turbo's pretraining of up to Sep 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e2d763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0534b7ca-0740-4a2d-9145-deddbd0fa2ee', 'be551dc2-73f3-4356-bc5a-199fb78a1f5b']\n",
      "Loaded 2 docs\n"
     ]
    }
   ],
   "source": [
    "filename_fn = lambda filename: {'file_name': filename}\n",
    "pdfhtml_docs = SimpleDirectoryReader(input_dir=data_dir, exclude_hidden=True, file_metadata=filename_fn).load_data()\n",
    "print([x.doc_id for x in pdfhtml_docs])\n",
    "print(f\"Loaded {len(pdfhtml_docs)} docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba98350",
   "metadata": {},
   "source": [
    "## Build index\n",
    "\n",
    "With all the data loaded, we can construct the index for the chatbot. There are 4 types of indexing: Summary index, VectorStore Index, Tree Index and Keyword Table Index. Here we are using VectorStore Index, which is also one of the most common types of indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5884ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# for more info on service context, refer to \n",
    "# https://gpt-index.readthedocs.io/en/latest/core_modules/supporting_modules/service_context.html\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0) # degree of randomness from 0 to 1. \n",
    ")\n",
    "docs = pdfhtml_docs \n",
    "index = GPTVectorStoreIndex.from_documents(documents=docs, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a86885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the output as a vector store so that we can refer to this \n",
    "# instead of running the embedding model above aagin\n",
    "\n",
    "index.storage_context.persist(persist_dir=\"./data/index.vecstore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e020cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
